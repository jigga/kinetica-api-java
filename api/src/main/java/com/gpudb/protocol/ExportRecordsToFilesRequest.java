/*
 *  This file was autogenerated by the Kinetica schema processor.
 *
 *  DO NOT EDIT DIRECTLY.
 */
package com.gpudb.protocol;

import java.util.LinkedHashMap;
import java.util.Map;
import org.apache.avro.Schema;
import org.apache.avro.SchemaBuilder;
import org.apache.avro.generic.GenericData;
import org.apache.avro.generic.IndexedRecord;

/**
 * A set of parameters for {@link
 * com.gpudb.GPUdb#exportRecordsToFiles(ExportRecordsToFilesRequest)
 * GPUdb.exportRecordsToFiles}.
 * <p>
 * Export records from a table to files. All tables can be exported, in full or
 * partial (see {@link Options#COLUMNS_TO_EXPORT COLUMNS_TO_EXPORT} and {@link
 * Options#COLUMNS_TO_SKIP COLUMNS_TO_SKIP}). Additional filtering can be
 * applied when using export table with expression through SQL. Default
 * destination is KIFS, though other storage types (Azure, S3, GCS, and HDFS)
 * are supported through {@link Options#DATASINK_NAME DATASINK_NAME}; see
 * {@link com.gpudb.GPUdb#createDatasink(CreateDatasinkRequest)
 * GPUdb.createDatasink}.
 * <p>
 * Server's local file system is not supported.  Default file format is
 * delimited text. See options for different file types and different options
 * for each file type.  Table is saved to a single file if within max file size
 * limits (may vary depending on datasink type).  If not, then table is split
 * into multiple files; these may be smaller than the max size limit.
 * <p>
 * All filenames created are returned in the response.
 */
public class ExportRecordsToFilesRequest implements IndexedRecord {
    private static final Schema schema$ = SchemaBuilder
            .record("ExportRecordsToFilesRequest")
            .namespace("com.gpudb")
            .fields()
                .name("tableName").type().stringType().noDefault()
                .name("filepath").type().stringType().noDefault()
                .name("options").type().map().values().stringType().noDefault()
            .endRecord();

    /**
     * This method supports the Avro framework and is not intended to be called
     * directly by the user.
     *
     * @return The schema for the class.
     */
    public static Schema getClassSchema() {
        return schema$;
    }

    /**
     * A set of string constants for the {@link ExportRecordsToFilesRequest}
     * parameter {@link #getOptions() options}.
     * <p>
     * Optional parameters.
     */
    public static final class Options {
        /**
         * Number of records to be exported as a batch. The default value is
         * '1000000'.
         */
        public static final String BATCH_SIZE = "batch_size";

        /**
         * For each source column specified, applies the column-property-bound
         * format.  Currently supported column properties include date, time, &
         * datetime. The parameter value must be formatted as a JSON string of
         * maps of column names to maps of column properties to their
         * corresponding column formats, e.g., '{ "order_date" : { "date" :
         * "%Y.%m.%d" }, "order_time" : { "time" : "%H:%M:%S" } }'.
         * <p>
         * See {@link Options#DEFAULT_COLUMN_FORMATS DEFAULT_COLUMN_FORMATS}
         * for valid format syntax.
         */
        public static final String COLUMN_FORMATS = "column_formats";

        /**
         * Specifies a comma-delimited list of columns from the source table to
         * export, written to the output file in the order they are given.
         * <p>
         * Column names can be provided, in which case the target file will use
         * those names as the column headers as well.
         * <p>
         * Alternatively, column numbers can be specified--discretely or as a
         * range.  For example, a value of '5,7,1..3' will write values from
         * the fifth column in the source table into the first column in the
         * target file, from the seventh column in the source table into the
         * second column in the target file, and from the first through third
         * columns in the source table into the third through fifth columns in
         * the target file.
         * <p>
         * Mutually exclusive with {@link Options#COLUMNS_TO_SKIP
         * COLUMNS_TO_SKIP}.
         */
        public static final String COLUMNS_TO_EXPORT = "columns_to_export";

        /**
         * Comma-separated list of column names or column numbers to not
         * export.  All columns in the source table not specified will be
         * written to the target file in the order they appear in the table
         * definition.  Mutually exclusive with {@link
         * Options#COLUMNS_TO_EXPORT COLUMNS_TO_EXPORT}.
         */
        public static final String COLUMNS_TO_SKIP = "columns_to_skip";

        /**
         * Datasink name, created using {@link
         * com.gpudb.GPUdb#createDatasink(CreateDatasinkRequest)
         * GPUdb.createDatasink}.
         */
        public static final String DATASINK_NAME = "datasink_name";

        /**
         * Specifies the default format to use to write data.  Currently
         * supported column properties include date, time, & datetime.  This
         * default column-property-bound format can be overridden by specifying
         * a column property & format for a given source column in {@link
         * Options#COLUMN_FORMATS COLUMN_FORMATS}. For each specified
         * annotation, the format will apply to all columns with that
         * annotation unless custom {@link Options#COLUMN_FORMATS
         * COLUMN_FORMATS} for that annotation are specified.
         * <p>
         * The parameter value must be formatted as a JSON string that is a map
         * of column properties to their respective column formats, e.g., '{
         * "date" : "%Y.%m.%d", "time" : "%H:%M:%S" }'.  Column formats are
         * specified as a string of control characters and plain text. The
         * supported control characters are 'Y', 'm', 'd', 'H', 'M', 'S', and
         * 's', which follow the Linux 'strptime()' specification, as well as
         * 's', which specifies seconds and fractional seconds (though the
         * fractional component will be truncated past milliseconds).
         * <p>
         * Formats for the 'date' annotation must include the 'Y', 'm', and 'd'
         * control characters. Formats for the 'time' annotation must include
         * the 'H', 'M', and either 'S' or 's' (but not both) control
         * characters. Formats for the 'datetime' annotation meet both the
         * 'date' and 'time' control character requirements. For example,
         * '{"datetime" : "%m/%d/%Y %H:%M:%S" }' would be used to write text as
         * "05/04/2000 12:12:11"
         */
        public static final String DEFAULT_COLUMN_FORMATS = "default_column_formats";

        /**
         * Save DDL to a separate file. The default value is 'false'.
         */
        public static final String EXPORT_DDL = "export_ddl";

        /**
         * Extension to give the export file. The default value is '.csv'.
         */
        public static final String FILE_EXTENSION = "file_extension";

        /**
         * Specifies the file format to use when exporting data.
         * Supported values:
         * <ul>
         *     <li>{@link Options#DELIMITED_TEXT DELIMITED_TEXT}: Delimited
         *         text file format; e.g., CSV, TSV, PSV, etc.
         *     <li>{@link Options#PARQUET PARQUET}
         * </ul>
         * The default value is {@link Options#DELIMITED_TEXT DELIMITED_TEXT}.
         */
        public static final String FILE_TYPE = "file_type";

        /**
         * Delimited text file format; e.g., CSV, TSV, PSV, etc.
         */
        public static final String DELIMITED_TEXT = "delimited_text";

        public static final String PARQUET = "parquet";

        /**
         * Whether to include a Kinetica proprietary header. Will not be
         * written if {@link Options#TEXT_HAS_HEADER TEXT_HAS_HEADER} is {@link
         * Options#FALSE FALSE}.
         * Supported values:
         * <ul>
         *     <li>{@link Options#TRUE TRUE}
         *     <li>{@link Options#FALSE FALSE}
         * </ul>
         * The default value is {@link Options#FALSE FALSE}.
         */
        public static final String KINETICA_HEADER = "kinetica_header";

        public static final String TRUE = "true";
        public static final String FALSE = "false";

        /**
         * If a Kinetica proprietary header is included, then specify a
         * property separator. Different from column delimiter. The default
         * value is '|'.
         */
        public static final String KINETICA_HEADER_DELIMITER = "kinetica_header_delimiter";

        /**
         * File compression type. GZip can be applied to text and Parquet
         * files.  Snappy can only be applied to Parquet files, and is the
         * default compression for them.
         * Supported values:
         * <ul>
         *     <li>{@link Options#UNCOMPRESSED UNCOMPRESSED}
         *     <li>{@link Options#SNAPPY SNAPPY}
         *     <li>{@link Options#GZIP GZIP}
         * </ul>
         */
        public static final String COMPRESSION_TYPE = "compression_type";

        public static final String UNCOMPRESSED = "uncompressed";
        public static final String SNAPPY = "snappy";
        public static final String GZIP = "gzip";

        /**
         * Save records to a single file. This option may be ignored if file
         * size exceeds internal file size limits (this limit will differ on
         * different targets).
         * Supported values:
         * <ul>
         *     <li>{@link Options#TRUE TRUE}
         *     <li>{@link Options#FALSE FALSE}
         *     <li>{@link Options#OVERWRITE OVERWRITE}
         * </ul>
         * The default value is {@link Options#TRUE TRUE}.
         */
        public static final String SINGLE_FILE = "single_file";

        public static final String OVERWRITE = "overwrite";

        /**
         * Specifies the character to write out to delimit field values and
         * field names in the header (if present).
         * <p>
         * For {@link Options#DELIMITED_TEXT DELIMITED_TEXT} {@link
         * Options#FILE_TYPE FILE_TYPE} only. The default value is ','.
         */
        public static final String TEXT_DELIMITER = "text_delimiter";

        /**
         * Indicates whether to write out a header row.
         * <p>
         * For {@link Options#DELIMITED_TEXT DELIMITED_TEXT} {@link
         * Options#FILE_TYPE FILE_TYPE} only.
         * Supported values:
         * <ul>
         *     <li>{@link Options#TRUE TRUE}
         *     <li>{@link Options#FALSE FALSE}
         * </ul>
         * The default value is {@link Options#TRUE TRUE}.
         */
        public static final String TEXT_HAS_HEADER = "text_has_header";

        /**
         * Specifies the character string that should be written out for the
         * null value in the data.
         * <p>
         * For {@link Options#DELIMITED_TEXT DELIMITED_TEXT} {@link
         * Options#FILE_TYPE FILE_TYPE} only. The default value is '\N'.
         */
        public static final String TEXT_NULL_STRING = "text_null_string";

        private Options() {  }
    }

    private String tableName;
    private String filepath;
    private Map<String, String> options;

    /**
     * Constructs an ExportRecordsToFilesRequest object with default
     * parameters.
     */
    public ExportRecordsToFilesRequest() {
        tableName = "";
        filepath = "";
        options = new LinkedHashMap<>();
    }

    /**
     * Constructs an ExportRecordsToFilesRequest object with the specified
     * parameters.
     *
     * @param filepath  Path to data export target.  If {@code filepath} has a
     *                  file extension, it is read as the name of a file. If
     *                  {@code filepath} is a directory, then the source table
     *                  name with a random UUID appended will be used as the
     *                  name of each exported file, all written to that
     *                  directory. If filepath is a filename, then all exported
     *                  files will have a random UUID appended to the given
     *                  name.  In either case, the target directory specified
     *                  or implied must exist.  The names of all exported files
     *                  are returned in the response.
     * @param options  Optional parameters.
     *                 <ul>
     *                     <li>{@link Options#BATCH_SIZE BATCH_SIZE}: Number of
     *                         records to be exported as a batch. The default
     *                         value is '1000000'.
     *                     <li>{@link Options#COLUMN_FORMATS COLUMN_FORMATS}:
     *                         For each source column specified, applies the
     *                         column-property-bound format.  Currently
     *                         supported column properties include date, time,
     *                         & datetime. The parameter value must be
     *                         formatted as a JSON string of maps of column
     *                         names to maps of column properties to their
     *                         corresponding column formats, e.g., '{
     *                         "order_date" : { "date" : "%Y.%m.%d" },
     *                         "order_time" : { "time" : "%H:%M:%S" } }'.  See
     *                         {@link Options#DEFAULT_COLUMN_FORMATS
     *                         DEFAULT_COLUMN_FORMATS} for valid format syntax.
     *                     <li>{@link Options#COLUMNS_TO_EXPORT
     *                         COLUMNS_TO_EXPORT}: Specifies a comma-delimited
     *                         list of columns from the source table to export,
     *                         written to the output file in the order they are
     *                         given.  Column names can be provided, in which
     *                         case the target file will use those names as the
     *                         column headers as well.  Alternatively, column
     *                         numbers can be specified--discretely or as a
     *                         range.  For example, a value of '5,7,1..3' will
     *                         write values from the fifth column in the source
     *                         table into the first column in the target file,
     *                         from the seventh column in the source table into
     *                         the second column in the target file, and from
     *                         the first through third columns in the source
     *                         table into the third through fifth columns in
     *                         the target file.  Mutually exclusive with {@link
     *                         Options#COLUMNS_TO_SKIP COLUMNS_TO_SKIP}.
     *                     <li>{@link Options#COLUMNS_TO_SKIP COLUMNS_TO_SKIP}:
     *                         Comma-separated list of column names or column
     *                         numbers to not export.  All columns in the
     *                         source table not specified will be written to
     *                         the target file in the order they appear in the
     *                         table definition.  Mutually exclusive with
     *                         {@link Options#COLUMNS_TO_EXPORT
     *                         COLUMNS_TO_EXPORT}.
     *                     <li>{@link Options#DATASINK_NAME DATASINK_NAME}:
     *                         Datasink name, created using {@link
     *                         com.gpudb.GPUdb#createDatasink(CreateDatasinkRequest)
     *                         GPUdb.createDatasink}.
     *                     <li>{@link Options#DEFAULT_COLUMN_FORMATS
     *                         DEFAULT_COLUMN_FORMATS}: Specifies the default
     *                         format to use to write data.  Currently
     *                         supported column properties include date, time,
     *                         & datetime.  This default column-property-bound
     *                         format can be overridden by specifying a column
     *                         property & format for a given source column in
     *                         {@link Options#COLUMN_FORMATS COLUMN_FORMATS}.
     *                         For each specified annotation, the format will
     *                         apply to all columns with that annotation unless
     *                         custom {@link Options#COLUMN_FORMATS
     *                         COLUMN_FORMATS} for that annotation are
     *                         specified.  The parameter value must be
     *                         formatted as a JSON string that is a map of
     *                         column properties to their respective column
     *                         formats, e.g., '{ "date" : "%Y.%m.%d", "time" :
     *                         "%H:%M:%S" }'.  Column formats are specified as
     *                         a string of control characters and plain text.
     *                         The supported control characters are 'Y', 'm',
     *                         'd', 'H', 'M', 'S', and 's', which follow the
     *                         Linux 'strptime()' specification, as well as
     *                         's', which specifies seconds and fractional
     *                         seconds (though the fractional component will be
     *                         truncated past milliseconds).  Formats for the
     *                         'date' annotation must include the 'Y', 'm', and
     *                         'd' control characters. Formats for the 'time'
     *                         annotation must include the 'H', 'M', and either
     *                         'S' or 's' (but not both) control characters.
     *                         Formats for the 'datetime' annotation meet both
     *                         the 'date' and 'time' control character
     *                         requirements. For example, '{"datetime" :
     *                         "%m/%d/%Y %H:%M:%S" }' would be used to write
     *                         text as "05/04/2000 12:12:11"
     *                     <li>{@link Options#EXPORT_DDL EXPORT_DDL}: Save DDL
     *                         to a separate file. The default value is
     *                         'false'.
     *                     <li>{@link Options#FILE_EXTENSION FILE_EXTENSION}:
     *                         Extension to give the export file. The default
     *                         value is '.csv'.
     *                     <li>{@link Options#FILE_TYPE FILE_TYPE}: Specifies
     *                         the file format to use when exporting data.
     *                         Supported values:
     *                         <ul>
     *                             <li>{@link Options#DELIMITED_TEXT
     *                                 DELIMITED_TEXT}: Delimited text file
     *                                 format; e.g., CSV, TSV, PSV, etc.
     *                             <li>{@link Options#PARQUET PARQUET}
     *                         </ul>
     *                         The default value is {@link
     *                         Options#DELIMITED_TEXT DELIMITED_TEXT}.
     *                     <li>{@link Options#KINETICA_HEADER KINETICA_HEADER}:
     *                         Whether to include a Kinetica proprietary
     *                         header. Will not be written if {@link
     *                         Options#TEXT_HAS_HEADER TEXT_HAS_HEADER} is
     *                         {@link Options#FALSE FALSE}.
     *                         Supported values:
     *                         <ul>
     *                             <li>{@link Options#TRUE TRUE}
     *                             <li>{@link Options#FALSE FALSE}
     *                         </ul>
     *                         The default value is {@link Options#FALSE
     *                         FALSE}.
     *                     <li>{@link Options#KINETICA_HEADER_DELIMITER
     *                         KINETICA_HEADER_DELIMITER}: If a Kinetica
     *                         proprietary header is included, then specify a
     *                         property separator. Different from column
     *                         delimiter. The default value is '|'.
     *                     <li>{@link Options#COMPRESSION_TYPE
     *                         COMPRESSION_TYPE}: File compression type. GZip
     *                         can be applied to text and Parquet files.
     *                         Snappy can only be applied to Parquet files, and
     *                         is the default compression for them.
     *                         Supported values:
     *                         <ul>
     *                             <li>{@link Options#UNCOMPRESSED
     *                                 UNCOMPRESSED}
     *                             <li>{@link Options#SNAPPY SNAPPY}
     *                             <li>{@link Options#GZIP GZIP}
     *                         </ul>
     *                     <li>{@link Options#SINGLE_FILE SINGLE_FILE}: Save
     *                         records to a single file. This option may be
     *                         ignored if file size exceeds internal file size
     *                         limits (this limit will differ on different
     *                         targets).
     *                         Supported values:
     *                         <ul>
     *                             <li>{@link Options#TRUE TRUE}
     *                             <li>{@link Options#FALSE FALSE}
     *                             <li>{@link Options#OVERWRITE OVERWRITE}
     *                         </ul>
     *                         The default value is {@link Options#TRUE TRUE}.
     *                     <li>{@link Options#TEXT_DELIMITER TEXT_DELIMITER}:
     *                         Specifies the character to write out to delimit
     *                         field values and field names in the header (if
     *                         present).  For {@link Options#DELIMITED_TEXT
     *                         DELIMITED_TEXT} {@link Options#FILE_TYPE
     *                         FILE_TYPE} only. The default value is ','.
     *                     <li>{@link Options#TEXT_HAS_HEADER TEXT_HAS_HEADER}:
     *                         Indicates whether to write out a header row.
     *                         For {@link Options#DELIMITED_TEXT
     *                         DELIMITED_TEXT} {@link Options#FILE_TYPE
     *                         FILE_TYPE} only.
     *                         Supported values:
     *                         <ul>
     *                             <li>{@link Options#TRUE TRUE}
     *                             <li>{@link Options#FALSE FALSE}
     *                         </ul>
     *                         The default value is {@link Options#TRUE TRUE}.
     *                     <li>{@link Options#TEXT_NULL_STRING
     *                         TEXT_NULL_STRING}: Specifies the character
     *                         string that should be written out for the null
     *                         value in the data.  For {@link
     *                         Options#DELIMITED_TEXT DELIMITED_TEXT} {@link
     *                         Options#FILE_TYPE FILE_TYPE} only. The default
     *                         value is '\N'.
     *                 </ul>
     *                 The default value is an empty {@link Map}.
     */
    public ExportRecordsToFilesRequest(String tableName, String filepath, Map<String, String> options) {
        this.tableName = (tableName == null) ? "" : tableName;
        this.filepath = (filepath == null) ? "" : filepath;
        this.options = (options == null) ? new LinkedHashMap<String, String>() : options;
    }

    /**
     * @return The current value of {@code tableName}.
     */
    public String getTableName() {
        return tableName;
    }

    /**
     * @param tableName  The new value for {@code tableName}.
     *
     * @return {@code this} to mimic the builder pattern.
     */
    public ExportRecordsToFilesRequest setTableName(String tableName) {
        this.tableName = (tableName == null) ? "" : tableName;
        return this;
    }

    /**
     * Path to data export target.  If {@link #getFilepath() filepath} has a
     * file extension, it is read as the name of a file. If {@link
     * #getFilepath() filepath} is a directory, then the source table name with
     * a random UUID appended will be used as the name of each exported file,
     * all written to that directory. If filepath is a filename, then all
     * exported files will have a random UUID appended to the given name.  In
     * either case, the target directory specified or implied must exist.  The
     * names of all exported files are returned in the response.
     *
     * @return The current value of {@code filepath}.
     */
    public String getFilepath() {
        return filepath;
    }

    /**
     * Path to data export target.  If {@link #getFilepath() filepath} has a
     * file extension, it is read as the name of a file. If {@link
     * #getFilepath() filepath} is a directory, then the source table name with
     * a random UUID appended will be used as the name of each exported file,
     * all written to that directory. If filepath is a filename, then all
     * exported files will have a random UUID appended to the given name.  In
     * either case, the target directory specified or implied must exist.  The
     * names of all exported files are returned in the response.
     *
     * @param filepath  The new value for {@code filepath}.
     *
     * @return {@code this} to mimic the builder pattern.
     */
    public ExportRecordsToFilesRequest setFilepath(String filepath) {
        this.filepath = (filepath == null) ? "" : filepath;
        return this;
    }

    /**
     * Optional parameters.
     * <ul>
     *     <li>{@link Options#BATCH_SIZE BATCH_SIZE}: Number of records to be
     *         exported as a batch. The default value is '1000000'.
     *     <li>{@link Options#COLUMN_FORMATS COLUMN_FORMATS}: For each source
     *         column specified, applies the column-property-bound format.
     *         Currently supported column properties include date, time, &
     *         datetime. The parameter value must be formatted as a JSON string
     *         of maps of column names to maps of column properties to their
     *         corresponding column formats, e.g., '{ "order_date" : { "date" :
     *         "%Y.%m.%d" }, "order_time" : { "time" : "%H:%M:%S" } }'.  See
     *         {@link Options#DEFAULT_COLUMN_FORMATS DEFAULT_COLUMN_FORMATS}
     *         for valid format syntax.
     *     <li>{@link Options#COLUMNS_TO_EXPORT COLUMNS_TO_EXPORT}: Specifies a
     *         comma-delimited list of columns from the source table to export,
     *         written to the output file in the order they are given.  Column
     *         names can be provided, in which case the target file will use
     *         those names as the column headers as well.  Alternatively,
     *         column numbers can be specified--discretely or as a range.  For
     *         example, a value of '5,7,1..3' will write values from the fifth
     *         column in the source table into the first column in the target
     *         file, from the seventh column in the source table into the
     *         second column in the target file, and from the first through
     *         third columns in the source table into the third through fifth
     *         columns in the target file.  Mutually exclusive with {@link
     *         Options#COLUMNS_TO_SKIP COLUMNS_TO_SKIP}.
     *     <li>{@link Options#COLUMNS_TO_SKIP COLUMNS_TO_SKIP}: Comma-separated
     *         list of column names or column numbers to not export.  All
     *         columns in the source table not specified will be written to the
     *         target file in the order they appear in the table definition.
     *         Mutually exclusive with {@link Options#COLUMNS_TO_EXPORT
     *         COLUMNS_TO_EXPORT}.
     *     <li>{@link Options#DATASINK_NAME DATASINK_NAME}: Datasink name,
     *         created using {@link
     *         com.gpudb.GPUdb#createDatasink(CreateDatasinkRequest)
     *         GPUdb.createDatasink}.
     *     <li>{@link Options#DEFAULT_COLUMN_FORMATS DEFAULT_COLUMN_FORMATS}:
     *         Specifies the default format to use to write data.  Currently
     *         supported column properties include date, time, & datetime.
     *         This default column-property-bound format can be overridden by
     *         specifying a column property & format for a given source column
     *         in {@link Options#COLUMN_FORMATS COLUMN_FORMATS}. For each
     *         specified annotation, the format will apply to all columns with
     *         that annotation unless custom {@link Options#COLUMN_FORMATS
     *         COLUMN_FORMATS} for that annotation are specified.  The
     *         parameter value must be formatted as a JSON string that is a map
     *         of column properties to their respective column formats, e.g.,
     *         '{ "date" : "%Y.%m.%d", "time" : "%H:%M:%S" }'.  Column formats
     *         are specified as a string of control characters and plain text.
     *         The supported control characters are 'Y', 'm', 'd', 'H', 'M',
     *         'S', and 's', which follow the Linux 'strptime()' specification,
     *         as well as 's', which specifies seconds and fractional seconds
     *         (though the fractional component will be truncated past
     *         milliseconds).  Formats for the 'date' annotation must include
     *         the 'Y', 'm', and 'd' control characters. Formats for the 'time'
     *         annotation must include the 'H', 'M', and either 'S' or 's' (but
     *         not both) control characters. Formats for the 'datetime'
     *         annotation meet both the 'date' and 'time' control character
     *         requirements. For example, '{"datetime" : "%m/%d/%Y %H:%M:%S" }'
     *         would be used to write text as "05/04/2000 12:12:11"
     *     <li>{@link Options#EXPORT_DDL EXPORT_DDL}: Save DDL to a separate
     *         file. The default value is 'false'.
     *     <li>{@link Options#FILE_EXTENSION FILE_EXTENSION}: Extension to give
     *         the export file. The default value is '.csv'.
     *     <li>{@link Options#FILE_TYPE FILE_TYPE}: Specifies the file format
     *         to use when exporting data.
     *         Supported values:
     *         <ul>
     *             <li>{@link Options#DELIMITED_TEXT DELIMITED_TEXT}: Delimited
     *                 text file format; e.g., CSV, TSV, PSV, etc.
     *             <li>{@link Options#PARQUET PARQUET}
     *         </ul>
     *         The default value is {@link Options#DELIMITED_TEXT
     *         DELIMITED_TEXT}.
     *     <li>{@link Options#KINETICA_HEADER KINETICA_HEADER}: Whether to
     *         include a Kinetica proprietary header. Will not be written if
     *         {@link Options#TEXT_HAS_HEADER TEXT_HAS_HEADER} is {@link
     *         Options#FALSE FALSE}.
     *         Supported values:
     *         <ul>
     *             <li>{@link Options#TRUE TRUE}
     *             <li>{@link Options#FALSE FALSE}
     *         </ul>
     *         The default value is {@link Options#FALSE FALSE}.
     *     <li>{@link Options#KINETICA_HEADER_DELIMITER
     *         KINETICA_HEADER_DELIMITER}: If a Kinetica proprietary header is
     *         included, then specify a property separator. Different from
     *         column delimiter. The default value is '|'.
     *     <li>{@link Options#COMPRESSION_TYPE COMPRESSION_TYPE}: File
     *         compression type. GZip can be applied to text and Parquet files.
     *         Snappy can only be applied to Parquet files, and is the default
     *         compression for them.
     *         Supported values:
     *         <ul>
     *             <li>{@link Options#UNCOMPRESSED UNCOMPRESSED}
     *             <li>{@link Options#SNAPPY SNAPPY}
     *             <li>{@link Options#GZIP GZIP}
     *         </ul>
     *     <li>{@link Options#SINGLE_FILE SINGLE_FILE}: Save records to a
     *         single file. This option may be ignored if file size exceeds
     *         internal file size limits (this limit will differ on different
     *         targets).
     *         Supported values:
     *         <ul>
     *             <li>{@link Options#TRUE TRUE}
     *             <li>{@link Options#FALSE FALSE}
     *             <li>{@link Options#OVERWRITE OVERWRITE}
     *         </ul>
     *         The default value is {@link Options#TRUE TRUE}.
     *     <li>{@link Options#TEXT_DELIMITER TEXT_DELIMITER}: Specifies the
     *         character to write out to delimit field values and field names
     *         in the header (if present).  For {@link Options#DELIMITED_TEXT
     *         DELIMITED_TEXT} {@link Options#FILE_TYPE FILE_TYPE} only. The
     *         default value is ','.
     *     <li>{@link Options#TEXT_HAS_HEADER TEXT_HAS_HEADER}: Indicates
     *         whether to write out a header row.  For {@link
     *         Options#DELIMITED_TEXT DELIMITED_TEXT} {@link Options#FILE_TYPE
     *         FILE_TYPE} only.
     *         Supported values:
     *         <ul>
     *             <li>{@link Options#TRUE TRUE}
     *             <li>{@link Options#FALSE FALSE}
     *         </ul>
     *         The default value is {@link Options#TRUE TRUE}.
     *     <li>{@link Options#TEXT_NULL_STRING TEXT_NULL_STRING}: Specifies the
     *         character string that should be written out for the null value
     *         in the data.  For {@link Options#DELIMITED_TEXT DELIMITED_TEXT}
     *         {@link Options#FILE_TYPE FILE_TYPE} only. The default value is
     *         '\N'.
     * </ul>
     * The default value is an empty {@link Map}.
     *
     * @return The current value of {@code options}.
     */
    public Map<String, String> getOptions() {
        return options;
    }

    /**
     * Optional parameters.
     * <ul>
     *     <li>{@link Options#BATCH_SIZE BATCH_SIZE}: Number of records to be
     *         exported as a batch. The default value is '1000000'.
     *     <li>{@link Options#COLUMN_FORMATS COLUMN_FORMATS}: For each source
     *         column specified, applies the column-property-bound format.
     *         Currently supported column properties include date, time, &
     *         datetime. The parameter value must be formatted as a JSON string
     *         of maps of column names to maps of column properties to their
     *         corresponding column formats, e.g., '{ "order_date" : { "date" :
     *         "%Y.%m.%d" }, "order_time" : { "time" : "%H:%M:%S" } }'.  See
     *         {@link Options#DEFAULT_COLUMN_FORMATS DEFAULT_COLUMN_FORMATS}
     *         for valid format syntax.
     *     <li>{@link Options#COLUMNS_TO_EXPORT COLUMNS_TO_EXPORT}: Specifies a
     *         comma-delimited list of columns from the source table to export,
     *         written to the output file in the order they are given.  Column
     *         names can be provided, in which case the target file will use
     *         those names as the column headers as well.  Alternatively,
     *         column numbers can be specified--discretely or as a range.  For
     *         example, a value of '5,7,1..3' will write values from the fifth
     *         column in the source table into the first column in the target
     *         file, from the seventh column in the source table into the
     *         second column in the target file, and from the first through
     *         third columns in the source table into the third through fifth
     *         columns in the target file.  Mutually exclusive with {@link
     *         Options#COLUMNS_TO_SKIP COLUMNS_TO_SKIP}.
     *     <li>{@link Options#COLUMNS_TO_SKIP COLUMNS_TO_SKIP}: Comma-separated
     *         list of column names or column numbers to not export.  All
     *         columns in the source table not specified will be written to the
     *         target file in the order they appear in the table definition.
     *         Mutually exclusive with {@link Options#COLUMNS_TO_EXPORT
     *         COLUMNS_TO_EXPORT}.
     *     <li>{@link Options#DATASINK_NAME DATASINK_NAME}: Datasink name,
     *         created using {@link
     *         com.gpudb.GPUdb#createDatasink(CreateDatasinkRequest)
     *         GPUdb.createDatasink}.
     *     <li>{@link Options#DEFAULT_COLUMN_FORMATS DEFAULT_COLUMN_FORMATS}:
     *         Specifies the default format to use to write data.  Currently
     *         supported column properties include date, time, & datetime.
     *         This default column-property-bound format can be overridden by
     *         specifying a column property & format for a given source column
     *         in {@link Options#COLUMN_FORMATS COLUMN_FORMATS}. For each
     *         specified annotation, the format will apply to all columns with
     *         that annotation unless custom {@link Options#COLUMN_FORMATS
     *         COLUMN_FORMATS} for that annotation are specified.  The
     *         parameter value must be formatted as a JSON string that is a map
     *         of column properties to their respective column formats, e.g.,
     *         '{ "date" : "%Y.%m.%d", "time" : "%H:%M:%S" }'.  Column formats
     *         are specified as a string of control characters and plain text.
     *         The supported control characters are 'Y', 'm', 'd', 'H', 'M',
     *         'S', and 's', which follow the Linux 'strptime()' specification,
     *         as well as 's', which specifies seconds and fractional seconds
     *         (though the fractional component will be truncated past
     *         milliseconds).  Formats for the 'date' annotation must include
     *         the 'Y', 'm', and 'd' control characters. Formats for the 'time'
     *         annotation must include the 'H', 'M', and either 'S' or 's' (but
     *         not both) control characters. Formats for the 'datetime'
     *         annotation meet both the 'date' and 'time' control character
     *         requirements. For example, '{"datetime" : "%m/%d/%Y %H:%M:%S" }'
     *         would be used to write text as "05/04/2000 12:12:11"
     *     <li>{@link Options#EXPORT_DDL EXPORT_DDL}: Save DDL to a separate
     *         file. The default value is 'false'.
     *     <li>{@link Options#FILE_EXTENSION FILE_EXTENSION}: Extension to give
     *         the export file. The default value is '.csv'.
     *     <li>{@link Options#FILE_TYPE FILE_TYPE}: Specifies the file format
     *         to use when exporting data.
     *         Supported values:
     *         <ul>
     *             <li>{@link Options#DELIMITED_TEXT DELIMITED_TEXT}: Delimited
     *                 text file format; e.g., CSV, TSV, PSV, etc.
     *             <li>{@link Options#PARQUET PARQUET}
     *         </ul>
     *         The default value is {@link Options#DELIMITED_TEXT
     *         DELIMITED_TEXT}.
     *     <li>{@link Options#KINETICA_HEADER KINETICA_HEADER}: Whether to
     *         include a Kinetica proprietary header. Will not be written if
     *         {@link Options#TEXT_HAS_HEADER TEXT_HAS_HEADER} is {@link
     *         Options#FALSE FALSE}.
     *         Supported values:
     *         <ul>
     *             <li>{@link Options#TRUE TRUE}
     *             <li>{@link Options#FALSE FALSE}
     *         </ul>
     *         The default value is {@link Options#FALSE FALSE}.
     *     <li>{@link Options#KINETICA_HEADER_DELIMITER
     *         KINETICA_HEADER_DELIMITER}: If a Kinetica proprietary header is
     *         included, then specify a property separator. Different from
     *         column delimiter. The default value is '|'.
     *     <li>{@link Options#COMPRESSION_TYPE COMPRESSION_TYPE}: File
     *         compression type. GZip can be applied to text and Parquet files.
     *         Snappy can only be applied to Parquet files, and is the default
     *         compression for them.
     *         Supported values:
     *         <ul>
     *             <li>{@link Options#UNCOMPRESSED UNCOMPRESSED}
     *             <li>{@link Options#SNAPPY SNAPPY}
     *             <li>{@link Options#GZIP GZIP}
     *         </ul>
     *     <li>{@link Options#SINGLE_FILE SINGLE_FILE}: Save records to a
     *         single file. This option may be ignored if file size exceeds
     *         internal file size limits (this limit will differ on different
     *         targets).
     *         Supported values:
     *         <ul>
     *             <li>{@link Options#TRUE TRUE}
     *             <li>{@link Options#FALSE FALSE}
     *             <li>{@link Options#OVERWRITE OVERWRITE}
     *         </ul>
     *         The default value is {@link Options#TRUE TRUE}.
     *     <li>{@link Options#TEXT_DELIMITER TEXT_DELIMITER}: Specifies the
     *         character to write out to delimit field values and field names
     *         in the header (if present).  For {@link Options#DELIMITED_TEXT
     *         DELIMITED_TEXT} {@link Options#FILE_TYPE FILE_TYPE} only. The
     *         default value is ','.
     *     <li>{@link Options#TEXT_HAS_HEADER TEXT_HAS_HEADER}: Indicates
     *         whether to write out a header row.  For {@link
     *         Options#DELIMITED_TEXT DELIMITED_TEXT} {@link Options#FILE_TYPE
     *         FILE_TYPE} only.
     *         Supported values:
     *         <ul>
     *             <li>{@link Options#TRUE TRUE}
     *             <li>{@link Options#FALSE FALSE}
     *         </ul>
     *         The default value is {@link Options#TRUE TRUE}.
     *     <li>{@link Options#TEXT_NULL_STRING TEXT_NULL_STRING}: Specifies the
     *         character string that should be written out for the null value
     *         in the data.  For {@link Options#DELIMITED_TEXT DELIMITED_TEXT}
     *         {@link Options#FILE_TYPE FILE_TYPE} only. The default value is
     *         '\N'.
     * </ul>
     * The default value is an empty {@link Map}.
     *
     * @param options  The new value for {@code options}.
     *
     * @return {@code this} to mimic the builder pattern.
     */
    public ExportRecordsToFilesRequest setOptions(Map<String, String> options) {
        this.options = (options == null) ? new LinkedHashMap<String, String>() : options;
        return this;
    }

    /**
     * This method supports the Avro framework and is not intended to be called
     * directly by the user.
     *
     * @return The schema object describing this class.
     */
    @Override
    public Schema getSchema() {
        return schema$;
    }

    /**
     * This method supports the Avro framework and is not intended to be called
     * directly by the user.
     *
     * @param index  the position of the field to get
     *
     * @return value of the field with the given index.
     *
     * @throws IndexOutOfBoundsException
     */
    @Override
    public Object get(int index) {
        switch (index) {
            case 0:
                return this.tableName;

            case 1:
                return this.filepath;

            case 2:
                return this.options;

            default:
                throw new IndexOutOfBoundsException("Invalid index specified.");
        }
    }

    /**
     * This method supports the Avro framework and is not intended to be called
     * directly by the user.
     *
     * @param index  the position of the field to set
     * @param value  the value to set
     *
     * @throws IndexOutOfBoundsException
     */
    @Override
    @SuppressWarnings("unchecked")
    public void put(int index, Object value) {
        switch (index) {
            case 0:
                this.tableName = (String)value;
                break;

            case 1:
                this.filepath = (String)value;
                break;

            case 2:
                this.options = (Map<String, String>)value;
                break;

            default:
                throw new IndexOutOfBoundsException("Invalid index specified.");
        }
    }

    @Override
    public boolean equals(Object obj) {
        if( obj == this ) {
            return true;
        }

        if( (obj == null) || (obj.getClass() != this.getClass()) ) {
            return false;
        }

        ExportRecordsToFilesRequest that = (ExportRecordsToFilesRequest)obj;

        return ( this.tableName.equals( that.tableName )
                 && this.filepath.equals( that.filepath )
                 && this.options.equals( that.options ) );
    }

    @Override
    public String toString() {
        GenericData gd = GenericData.get();
        StringBuilder builder = new StringBuilder();
        builder.append( "{" );
        builder.append( gd.toString( "tableName" ) );
        builder.append( ": " );
        builder.append( gd.toString( this.tableName ) );
        builder.append( ", " );
        builder.append( gd.toString( "filepath" ) );
        builder.append( ": " );
        builder.append( gd.toString( this.filepath ) );
        builder.append( ", " );
        builder.append( gd.toString( "options" ) );
        builder.append( ": " );
        builder.append( gd.toString( this.options ) );
        builder.append( "}" );

        return builder.toString();
    }

    @Override
    public int hashCode() {
        int hashCode = 1;
        hashCode = (31 * hashCode) + this.tableName.hashCode();
        hashCode = (31 * hashCode) + this.filepath.hashCode();
        hashCode = (31 * hashCode) + this.options.hashCode();
        return hashCode;
    }
}
