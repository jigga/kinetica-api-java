/*
 *  This file was autogenerated by the Kinetica schema processor.
 *
 *  DO NOT EDIT DIRECTLY.
 */
package com.gpudb.protocol;

import java.util.ArrayList;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;
import org.apache.avro.Schema;
import org.apache.avro.SchemaBuilder;
import org.apache.avro.generic.GenericData;
import org.apache.avro.generic.IndexedRecord;

/**
 * A set of results returned by {@link
 * com.gpudb.GPUdb#showDatasource(ShowDatasourceRequest) GPUdb.showDatasource}.
 */
public class ShowDatasourceResponse implements IndexedRecord {
    private static final Schema schema$ = SchemaBuilder
            .record("ShowDatasourceResponse")
            .namespace("com.gpudb")
            .fields()
                .name("datasourceNames").type().array().items().stringType().noDefault()
                .name("storageProviderTypes").type().array().items().stringType().noDefault()
                .name("additionalInfo").type().array().items().map().values().stringType().noDefault()
                .name("info").type().map().values().stringType().noDefault()
            .endRecord();

    /**
     * This method supports the Avro framework and is not intended to be called
     * directly by the user.
     *
     * @return The schema for the class.
     */
    public static Schema getClassSchema() {
        return schema$;
    }

    /**
     * A set of string constants for the {@link ShowDatasourceResponse}
     * parameter {@link #getStorageProviderTypes() storageProviderTypes}.
     * <p>
     * The storage provider type of the data sources named in {@link
     * #getDatasourceNames() datasourceNames}.
     */
    public static final class StorageProviderTypes {
        /**
         * Apache Hadoop Distributed File System
         */
        public static final String HDFS = "hdfs";

        /**
         * Amazon S3 bucket
         */
        public static final String S3 = "s3";

        private StorageProviderTypes() {  }
    }

    /**
     * A set of string constants for the {@link ShowDatasourceResponse}
     * parameter {@link #getAdditionalInfo() additionalInfo}.
     * <p>
     * Additional information about the respective data sources in {@link
     * #getDatasourceNames() datasourceNames}.
     */
    public static final class AdditionalInfo {
        /**
         * Location of the remote storage in
         * 'storage_provider_type://[storage_path[:storage_port]]' format
         */
        public static final String LOCATION = "location";

        /**
         * Name of the Amazon S3 bucket used as the data source
         */
        public static final String S3_BUCKET_NAME = "s3_bucket_name";

        /**
         * Name of the Amazon S3 region where the bucket is located
         */
        public static final String S3_REGION = "s3_region";

        /**
         * Kerberos key for the given HDFS user
         */
        public static final String HDFS_KERBEROS_KEYTAB = "hdfs_kerberos_keytab";

        /**
         * Name of the remote system user
         */
        public static final String USER_NAME = "user_name";

        private AdditionalInfo() {  }
    }

    private List<String> datasourceNames;
    private List<String> storageProviderTypes;
    private List<Map<String, String>> additionalInfo;
    private Map<String, String> info;

    /**
     * Constructs a ShowDatasourceResponse object with default parameters.
     */
    public ShowDatasourceResponse() {
    }

    /**
     * The data source names.
     *
     * @return The current value of {@code datasourceNames}.
     */
    public List<String> getDatasourceNames() {
        return datasourceNames;
    }

    /**
     * The data source names.
     *
     * @param datasourceNames  The new value for {@code datasourceNames}.
     *
     * @return {@code this} to mimic the builder pattern.
     */
    public ShowDatasourceResponse setDatasourceNames(List<String> datasourceNames) {
        this.datasourceNames = (datasourceNames == null) ? new ArrayList<String>() : datasourceNames;
        return this;
    }

    /**
     * The storage provider type of the data sources named in {@link
     * #getDatasourceNames() datasourceNames}.
     * Supported values:
     * <ul>
     *     <li>{@link StorageProviderTypes#HDFS HDFS}: Apache Hadoop
     *         Distributed File System
     *     <li>{@link StorageProviderTypes#S3 S3}: Amazon S3 bucket
     * </ul>
     *
     * @return The current value of {@code storageProviderTypes}.
     */
    public List<String> getStorageProviderTypes() {
        return storageProviderTypes;
    }

    /**
     * The storage provider type of the data sources named in {@link
     * #getDatasourceNames() datasourceNames}.
     * Supported values:
     * <ul>
     *     <li>{@link StorageProviderTypes#HDFS HDFS}: Apache Hadoop
     *         Distributed File System
     *     <li>{@link StorageProviderTypes#S3 S3}: Amazon S3 bucket
     * </ul>
     *
     * @param storageProviderTypes  The new value for {@code
     *                              storageProviderTypes}.
     *
     * @return {@code this} to mimic the builder pattern.
     */
    public ShowDatasourceResponse setStorageProviderTypes(List<String> storageProviderTypes) {
        this.storageProviderTypes = (storageProviderTypes == null) ? new ArrayList<String>() : storageProviderTypes;
        return this;
    }

    /**
     * Additional information about the respective data sources in {@link
     * #getDatasourceNames() datasourceNames}.
     * <ul>
     *     <li>{@link AdditionalInfo#LOCATION LOCATION}: Location of the remote
     *         storage in
     *         'storage_provider_type://[storage_path[:storage_port]]' format
     *     <li>{@link AdditionalInfo#S3_BUCKET_NAME S3_BUCKET_NAME}: Name of
     *         the Amazon S3 bucket used as the data source
     *     <li>{@link AdditionalInfo#S3_REGION S3_REGION}: Name of the Amazon
     *         S3 region where the bucket is located
     *     <li>{@link AdditionalInfo#HDFS_KERBEROS_KEYTAB
     *         HDFS_KERBEROS_KEYTAB}: Kerberos key for the given HDFS user
     *     <li>{@link AdditionalInfo#USER_NAME USER_NAME}: Name of the remote
     *         system user
     * </ul>
     *
     * @return The current value of {@code additionalInfo}.
     */
    public List<Map<String, String>> getAdditionalInfo() {
        return additionalInfo;
    }

    /**
     * Additional information about the respective data sources in {@link
     * #getDatasourceNames() datasourceNames}.
     * <ul>
     *     <li>{@link AdditionalInfo#LOCATION LOCATION}: Location of the remote
     *         storage in
     *         'storage_provider_type://[storage_path[:storage_port]]' format
     *     <li>{@link AdditionalInfo#S3_BUCKET_NAME S3_BUCKET_NAME}: Name of
     *         the Amazon S3 bucket used as the data source
     *     <li>{@link AdditionalInfo#S3_REGION S3_REGION}: Name of the Amazon
     *         S3 region where the bucket is located
     *     <li>{@link AdditionalInfo#HDFS_KERBEROS_KEYTAB
     *         HDFS_KERBEROS_KEYTAB}: Kerberos key for the given HDFS user
     *     <li>{@link AdditionalInfo#USER_NAME USER_NAME}: Name of the remote
     *         system user
     * </ul>
     *
     * @param additionalInfo  The new value for {@code additionalInfo}.
     *
     * @return {@code this} to mimic the builder pattern.
     */
    public ShowDatasourceResponse setAdditionalInfo(List<Map<String, String>> additionalInfo) {
        this.additionalInfo = (additionalInfo == null) ? new ArrayList<Map<String, String>>() : additionalInfo;
        return this;
    }

    /**
     * Additional information.
     *
     * @return The current value of {@code info}.
     */
    public Map<String, String> getInfo() {
        return info;
    }

    /**
     * Additional information.
     *
     * @param info  The new value for {@code info}.
     *
     * @return {@code this} to mimic the builder pattern.
     */
    public ShowDatasourceResponse setInfo(Map<String, String> info) {
        this.info = (info == null) ? new LinkedHashMap<String, String>() : info;
        return this;
    }

    /**
     * This method supports the Avro framework and is not intended to be called
     * directly by the user.
     *
     * @return The schema object describing this class.
     */
    @Override
    public Schema getSchema() {
        return schema$;
    }

    /**
     * This method supports the Avro framework and is not intended to be called
     * directly by the user.
     *
     * @param index  the position of the field to get
     *
     * @return value of the field with the given index.
     *
     * @throws IndexOutOfBoundsException
     */
    @Override
    public Object get(int index) {
        switch (index) {
            case 0:
                return this.datasourceNames;

            case 1:
                return this.storageProviderTypes;

            case 2:
                return this.additionalInfo;

            case 3:
                return this.info;

            default:
                throw new IndexOutOfBoundsException("Invalid index specified.");
        }
    }

    /**
     * This method supports the Avro framework and is not intended to be called
     * directly by the user.
     *
     * @param index  the position of the field to set
     * @param value  the value to set
     *
     * @throws IndexOutOfBoundsException
     */
    @Override
    @SuppressWarnings("unchecked")
    public void put(int index, Object value) {
        switch (index) {
            case 0:
                this.datasourceNames = (List<String>)value;
                break;

            case 1:
                this.storageProviderTypes = (List<String>)value;
                break;

            case 2:
                this.additionalInfo = (List<Map<String, String>>)value;
                break;

            case 3:
                this.info = (Map<String, String>)value;
                break;

            default:
                throw new IndexOutOfBoundsException("Invalid index specified.");
        }
    }

    @Override
    public boolean equals(Object obj) {
        if( obj == this ) {
            return true;
        }

        if( (obj == null) || (obj.getClass() != this.getClass()) ) {
            return false;
        }

        ShowDatasourceResponse that = (ShowDatasourceResponse)obj;

        return ( this.datasourceNames.equals( that.datasourceNames )
                 && this.storageProviderTypes.equals( that.storageProviderTypes )
                 && this.additionalInfo.equals( that.additionalInfo )
                 && this.info.equals( that.info ) );
    }

    @Override
    public String toString() {
        GenericData gd = GenericData.get();
        StringBuilder builder = new StringBuilder();
        builder.append( "{" );
        builder.append( gd.toString( "datasourceNames" ) );
        builder.append( ": " );
        builder.append( gd.toString( this.datasourceNames ) );
        builder.append( ", " );
        builder.append( gd.toString( "storageProviderTypes" ) );
        builder.append( ": " );
        builder.append( gd.toString( this.storageProviderTypes ) );
        builder.append( ", " );
        builder.append( gd.toString( "additionalInfo" ) );
        builder.append( ": " );
        builder.append( gd.toString( this.additionalInfo ) );
        builder.append( ", " );
        builder.append( gd.toString( "info" ) );
        builder.append( ": " );
        builder.append( gd.toString( this.info ) );
        builder.append( "}" );

        return builder.toString();
    }

    @Override
    public int hashCode() {
        int hashCode = 1;
        hashCode = (31 * hashCode) + this.datasourceNames.hashCode();
        hashCode = (31 * hashCode) + this.storageProviderTypes.hashCode();
        hashCode = (31 * hashCode) + this.additionalInfo.hashCode();
        hashCode = (31 * hashCode) + this.info.hashCode();
        return hashCode;
    }
}
